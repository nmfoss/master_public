{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils as u\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# feature selectors\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# scalers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# classifiers\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# samplers\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# calibration\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../pandas/lemma_delivered_merged_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_lemma_labeled_vocab.pkl')\n",
    "df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_lemma_full_vocab.pkl')\n",
    "df['is_nn'] = pd.read_pickle('../pandas/is_nn_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_corpus = df[(df['agg_label'] != -1) & (df['is_nn'] == False)]\n",
    "unlabeled_corpus = df[(df['agg_label'] == -1) & (df['is_nn'] == False)]\n",
    "\n",
    "target = 'agg_label'\n",
    "text = 'lemma_delivered'\n",
    "fasttext = 'ft'\n",
    "numeric = ['raw_len', 'raw_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, vali_X, train_y, vali_y = train_test_split(\n",
    "    labeled_corpus,\n",
    "    labeled_corpus[target],\n",
    "    test_size=0.4,\n",
    "    random_state=1,\n",
    "    stratify=labeled_corpus[target])\n",
    "\n",
    "test_X, validation_X, test_y, validation_y = train_test_split(\n",
    "    vali_X,\n",
    "    vali_y,\n",
    "    test_size=0.5,\n",
    "    random_state=1,\n",
    "    stratify=vali_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        return np.stack(df[self.col].to_numpy())\n",
    "\n",
    "def modeller(data, feats, vectorizer, scaler, selector, sampler, classifier):\n",
    "\n",
    "    features = []\n",
    "\n",
    "    if 'text' in feats:\n",
    "        features.append(\n",
    "            ('text', Pipeline([\n",
    "                ('article', u.ColumnSelector(feats['text'])),\n",
    "                ('vectorizer', vectorizer['vec'](**vectorizer['params'])),\n",
    "                #('selector', selector['sel'](**selector['params'])),\n",
    "            ]))\n",
    "        )\n",
    "\n",
    "    if 'numeric' in feats:\n",
    "        features.append(\n",
    "            ('numerical', Pipeline([\n",
    "                ('numeric', u.ColumnSelector(feats['numeric'])),\n",
    "                ('scaler', scaler['sca'](**scaler['params'])),\n",
    "            ]))\n",
    "        )\n",
    "\n",
    "    if 'ft' in feats:\n",
    "        features.append(\n",
    "            ('embeddings', Pipeline([\n",
    "                ('ft', FastTextSelector(feats['ft'])),\n",
    "                ('scaler', scaler['sca'](**scaler['params'])),\n",
    "            ]))\n",
    "        )\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('features', FeatureUnion(features)),\n",
    "        #('selector', selector['sel'](**selector['params'])),\n",
    "        ('sampler', sampler['smpl'](**sampler['params'])),\n",
    "        #('scaler', scaler['sca'](**scaler['params'])),\n",
    "        ('classifier', classifier['clf'](**classifier['params']))\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model.fit(data['train_X'], data['train_y'])\n",
    "    preds = model.predict(data['validation_X'])\n",
    "    probs = model.predict_proba(data['validation_X'])\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    if 'validation_y' in data:\n",
    "        metrics['acc'] = accuracy_score(data['validation_y'], preds)\n",
    "        metrics['prec'], metrics['reca'], metrics['fsco'], _ = precision_recall_fscore_support(data['validation_y'], preds, average='macro')\n",
    "        #print(acc, prec, reca, fsco)\n",
    "    \n",
    "    return preds, probs, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature combinations\n",
    "feats = [\n",
    "    #('TextOnly', {'text': text}),\n",
    "    #('FTOnly', {'ft': fasttext}),\n",
    "    ('Text+FT', {'text': text, 'ft': fasttext}),\n",
    "    #('Text+DLWC', {'text': text, 'numeric': numeric}),\n",
    "    #('All', {'text': text, 'numeric': numeric, 'ft': fasttext}),\n",
    "]\n",
    "\n",
    "\n",
    "# vectorizers\n",
    "vectorizers = [\n",
    "    #('No_vectorizer', u.PassThrough, [{}]),\n",
    "    ('TfidfVectorizer', TfidfVectorizer, [{'lowercase': False, 'max_df': 0.25}]),  \n",
    "]\n",
    "\n",
    "#corpus = ['empty']\n",
    "#fastt = False\n",
    "\n",
    "# feature selectors\n",
    "selectors = [\n",
    "    ('No_selector', u.PassThrough, [{}]),\n",
    "    #('SelectKBest', SelectKBest, [{'score_func': chi2, 'k': 40000}]),\n",
    "]\n",
    "\n",
    "# scalers\n",
    "scalers = [\n",
    "    #('No_scaling', u.PassThrough, [{}]),\n",
    "    ('MinMaxScaler', MinMaxScaler, [{'feature_range': (0,1)}]),\n",
    "]\n",
    "\n",
    "# classifiers\n",
    "\n",
    "clf = LinearSVC(**{'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01})\n",
    "\n",
    "classifiers = [\n",
    "    #('LinearSVC', LinearSVC, [{'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}]),\n",
    "    ('CalibratedClassifierCV_LinearSVC', CalibratedClassifierCV, [{'base_estimator': clf, 'method': 'isotonic', 'cv': 3}]),\n",
    "]\n",
    "\n",
    "# samplers\n",
    "samplers = [\n",
    "    #('No_sampling', u.PassThrough, [{}]),\n",
    "    ('TomekLinks', TomekLinks, [{'random_state': 1, 'sampling_strategy': 'majority', 'n_jobs': -1}]),\n",
    "]\n",
    "\n",
    "\n",
    "def model_caller(data):\n",
    "  \n",
    "    preds, probs, metrics = modeller(**{\n",
    "        'data': data,\n",
    "        'feats': feats[0][1],\n",
    "        'vectorizer': {\n",
    "            'vec': vectorizers[0][1],\n",
    "            'params': vectorizers[0][2][0]\n",
    "        },\n",
    "        'scaler': {\n",
    "            'sca': scalers[0][1],\n",
    "            'params': scalers[0][2][0]\n",
    "        },\n",
    "        'selector': {\n",
    "            'sel': selectors[0][1],\n",
    "            'params': selectors[0][2][0]\n",
    "        },\n",
    "        'sampler': {\n",
    "            'smpl': samplers[0][1],\n",
    "            'params': samplers[0][2][0]\n",
    "        },\n",
    "        'classifier': {\n",
    "            'clf': classifiers[0][1],\n",
    "            'params': classifiers[0][2][0]\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    model_title = {\n",
    "        'features': feats[0][0],\n",
    "        'vectorizer': vectorizers[0][0],\n",
    "        'scaler': scalers[0][0],\n",
    "        'selector': selectors[0][0],\n",
    "        'sampler': samplers[0][0],\n",
    "        'classifier': classifiers[0][0],\n",
    "    }\n",
    "    \n",
    "    print(model_title)\n",
    "    return preds, probs, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trash_y = [1 if x in [91, 92, 93] else 0 for x in train_y]\n",
    "validation_trash_y = [1 if x in [91, 92, 93] else 0 for x in validation_y]\n",
    "test_trash_y = [1 if x in [91, 92, 93] else 0 for x in test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': 'Text+FT', 'vectorizer': 'TfidfVectorizer', 'scaler': 'MinMaxScaler', 'selector': 'No_selector', 'sampler': 'TomekLinks', 'classifier': 'CalibratedClassifierCV_LinearSVC'}\n"
     ]
    }
   ],
   "source": [
    "data_in = {\n",
    "    'train_X': train_X,\n",
    "    'train_y': train_trash_y,\n",
    "    'validation_X': df\n",
    "}\n",
    "\n",
    "preds, probs, _ = model_caller(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9003219747786423"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds == test_trash_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_trash'] = [True if x == 1 else False for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_trash'].to_pickle('../pandas/is_trash_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[labeled_corpus.index][(~df.loc[labeled_corpus.index]['agg_label'].isin([91,92,93])) & (df.loc[labeled_corpus.index]['is_trash'] == True)]['agg_label'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7623"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[labeled_corpus.index]['agg_label'].isin([91,92,93]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764869"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[unlabeled_corpus.index]['is_trash'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
