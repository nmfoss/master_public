{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import utils as u\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# feature selectors\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# scalers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# classifiers\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# samplers\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# calibration\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../pandas/lemma_delivered_merged_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_lemma_labeled_vocab.pkl')\n",
    "df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_lemma_full_vocab.pkl')\n",
    "df['is_nn'] = pd.read_pickle('../pandas/is_nn_full.pkl')\n",
    "df['is_trash'] = pd.read_pickle('../pandas/is_trash_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_corpus = df[(df['agg_label'] != -1) & (df['is_nn'] == False)]\n",
    "unlabeled_corpus = df[(df['agg_label'] == -1) & (df['is_nn'] == False) & (df['is_trash'] == False)]\n",
    "\n",
    "target = 'agg_label'\n",
    "text = 'lemma_delivered'\n",
    "fasttext = 'ft'\n",
    "numeric = ['raw_len', 'raw_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, vali_X, train_y, vali_y = train_test_split(\n",
    "    labeled_corpus,\n",
    "    labeled_corpus[target],\n",
    "    test_size=0.4,\n",
    "    random_state=1,\n",
    "    stratify=labeled_corpus[target])\n",
    "\n",
    "test_X, validation_X, test_y, validation_y = train_test_split(\n",
    "    vali_X,\n",
    "    vali_y,\n",
    "    test_size=0.5,\n",
    "    random_state=1,\n",
    "    stratify=vali_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "clf_LinearSVC = LinearSVC(**{'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01})\n",
    "baseline_model = {\n",
    "    'title': 'baseline_model',\n",
    "    'features': ('Text+FT', {'text': text, 'ft': fasttext}),\n",
    "    'vectorizer': ('TfidfVectorizer', TfidfVectorizer, {'lowercase': False, 'max_df': 0.25}),\n",
    "    'scaler': ('MinMaxScaler', MinMaxScaler, {'feature_range': (0,1)}),\n",
    "    'sampler': ('TomekLinks', TomekLinks, {'random_state': 1, 'sampling_strategy': 'majority', 'n_jobs': -1}),\n",
    "    #'sampler': ('No_sampling', u.PassThrough, {}),\n",
    "    'classifier': ('CalibratedClassifierCV_LinearSVC', CalibratedClassifierCV, {'base_estimator': clf_LinearSVC, 'method': 'isotonic', 'cv': 3}),\n",
    "    #'classifier': ('LinearSVC', LinearSVC, {'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}),\n",
    "}\n",
    "\n",
    "quick_svm_model = {\n",
    "    'title': 'quick_svm_model',\n",
    "    'features': ('Text+FT', {'text': text}),\n",
    "    'vectorizer': ('TfidfVectorizer', TfidfVectorizer, {'lowercase': False, 'max_df': 0.25}),\n",
    "    'scaler': ('No_scaling', u.PassThrough, {}),\n",
    "    'sampler': ('No_sampling', u.PassThrough, {}),\n",
    "    'classifier': ('LinearSVC', LinearSVC, {'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}),\n",
    "}\n",
    "\n",
    "clf_ComplementNB = ComplementNB(**{'alpha': 0.2})\n",
    "quick_model = {\n",
    "    'title': 'quick_model',\n",
    "    'features': ('TextOnly', {'text': text}),\n",
    "    'vectorizer': ('TfidfVectorizer', TfidfVectorizer, {'lowercase': False, 'max_df': 0.25}),\n",
    "    'scaler': ('No_scaling', u.PassThrough, {}),\n",
    "    'sampler': ('No_sampling', u.PassThrough, {}),\n",
    "    'classifier': ('CalibratedClassifierCV_ComplementNB', CalibratedClassifierCV, {'base_estimator': clf_ComplementNB, 'method': 'isotonic', 'cv': 3}),\n",
    "    #'classifier': ('CalibratedClassifierCV_ComplementNB', CalibratedClassifierCV, {'base_estimator': clf_ComplementNB, 'cv': 3}),\n",
    "}\n",
    "\n",
    "clf_LogisticRegression = LogisticRegression(**{'solver': 'saga', 'tol': 0.0001, 'C': 8, 'n_jobs': -1, 'random_state': 1})\n",
    "log_model = {\n",
    "    'title': 'log_model',\n",
    "    'features': ('TextOnly', {'text': text}),\n",
    "    'vectorizer': ('TfidfVectorizer', TfidfVectorizer, {'lowercase': False, 'max_df': 0.25}),\n",
    "    'scaler': ('No_scaling', u.PassThrough, {}),\n",
    "    'sampler': ('No_sampling', u.PassThrough, {}),\n",
    "    'classifier': ('CalibratedClassifierCV_LogisticRegression', CalibratedClassifierCV, {'base_estimator': clf_LogisticRegression, 'method': 'isotonic', 'cv': 3}),\n",
    "}\n",
    "\n",
    "wordembed_model = {\n",
    "    'title': 'wordembed_model',\n",
    "    'features': ('FT', {'ft': fasttext}),\n",
    "    'vectorizer': ('TfidfVectorizer', u.PassThrough, {}),\n",
    "    'scaler': ('MinMaxScaler', MinMaxScaler, {'feature_range': (0,1)}),\n",
    "    #'sampler': ('TomekLinks', TomekLinks, {'random_state': 1, 'sampling_strategy': 'majority', 'n_jobs': -1}),\n",
    "    'sampler': ('No_sampling', u.PassThrough, {}),\n",
    "    'classifier': ('CalibratedClassifierCV_LinearSVC', CalibratedClassifierCV, {'base_estimator': clf_LinearSVC, 'method': 'isotonic', 'cv': 3}),\n",
    "    #'classifier': ('LinearSVC', LinearSVC, {'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        return np.stack(df[self.col].to_numpy())\n",
    "\n",
    "def modeller(data, model):\n",
    "\n",
    "    features = []\n",
    "\n",
    "    if 'text' in model['features'][1]:\n",
    "        features.append(\n",
    "            ('text', Pipeline([\n",
    "                ('article', u.ColumnSelector(model['features'][1]['text'])),\n",
    "                ('vectorizer', model['vectorizer'][1](**model['vectorizer'][2])),\n",
    "            ]))\n",
    "        )\n",
    "\n",
    "    if 'ft' in model['features'][1]:\n",
    "        features.append(\n",
    "            ('embeddings', Pipeline([\n",
    "                ('ft', FastTextSelector(model['features'][1]['ft'])),\n",
    "                ('scaler', model['scaler'][1](**model['scaler'][2])),\n",
    "            ]))\n",
    "        )\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('features', FeatureUnion(features)),\n",
    "        ('sampler', model['sampler'][1](**model['sampler'][2])),\n",
    "        ('classifier', model['classifier'][1](**model['classifier'][2]))\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model.fit(data['train_X'], data['train_y'])\n",
    "    preds = model.predict(data['validation_X'])\n",
    "    probs = model.predict_proba(data['validation_X'])\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    if 'validation_y' in data:\n",
    "        metrics['acc'] = accuracy_score(data['validation_y'], preds)\n",
    "        metrics['prec'], metrics['reca'], metrics['fsco'], _ = precision_recall_fscore_support(data['validation_y'], preds, average='macro')\n",
    "        #print(acc, prec, reca, fsco)\n",
    "    \n",
    "    return preds, probs, metrics, model['classifier'].classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
