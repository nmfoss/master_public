{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils as u\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "\n",
    "import murmurhash as mhash\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "# vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "\n",
    "# feature selectors\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "\n",
    "\n",
    "# scalers\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "# classifiers\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# samplers\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# calibration\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle('../pandas/lemma_delivered_merged_ft_s_dropped2_df.pkl')\n",
    "df = pd.read_pickle('../pandas/lemma_delivered_merged_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_lemma_full_vocab.pkl')\n",
    "df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_lemma_labeled_vocab.pkl')\n",
    "#df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_labeled_vocab.pkl')\n",
    "#df['ft'] = pd.read_pickle('../pandas/FT_TFIDF_full_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_nn'] = pd.read_pickle('../pandas/is_nn_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_corpus = df[(df['agg_label'] != -1) & (df['is_nn'] == False)]\n",
    "unlabeled_corpus = df[(df['agg_label'] == -1) & (df['is_nn'] == False)]\n",
    "\n",
    "#labeled_corpus = df[(df['agg_label'] != -1)]\n",
    "#labeled_corpus = df[(df['agg_label'] != -1) & (df['agg_label'] < 90)]\n",
    "#labeled_corpus = df[(df['agg_label'] != -1)]['lemma_delivered']\n",
    "#target = df[(df['agg_label'] != -1) & (df['agg_label'] < 90)]['agg_label']\n",
    "#target = df[(df['agg_label'] != -1)]['agg_label']\n",
    "#unlabeled_corpus = df[(df['agg_label'] == -1)]\n",
    "\n",
    "target = 'agg_label'\n",
    "text = 'lemma_delivered'\n",
    "fasttext = 'ft'\n",
    "numeric = ['raw_len', 'raw_word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, vali_X, train_y, vali_y = train_test_split(\n",
    "    labeled_corpus,\n",
    "    labeled_corpus[target],\n",
    "    test_size=0.4,\n",
    "    random_state=1,\n",
    "    stratify=labeled_corpus[target])\n",
    "\n",
    "test_X, validation_X, test_y, validation_y = train_test_split(\n",
    "    vali_X,\n",
    "    vali_y,\n",
    "    test_size=0.5,\n",
    "    random_state=1,\n",
    "    stratify=vali_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_lemma = np.loadtxt('stopwords_lemma.txt', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(txt):\n",
    "    p = re.compile(r\"\\d*([^\\d\\W]+)\\d*\")\n",
    "    result = []\n",
    "    for word in txt.split():\n",
    "        result.append(p.sub(r\"\\1\", word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer params\n",
    "TfidfVectorizer_params = list(ParameterGrid({\n",
    "    'strip_accents': ['ascii', 'unicode', None],\n",
    "    'max_df': [round(0.01*x, 2) for x in range(5,45,10)],\n",
    "    #'tokenizer': [lambda x: x.split(), None],\n",
    "    'lowercase': [True, False],\n",
    "    'max_features': [1000*x for x in range(10,50,10)] + [None],\n",
    "    #'stop_words': [list(stopwords_lemma), None],\n",
    "    #'norm': ['l2', None],\n",
    "    #'use_idf': [True, False]\n",
    "}))\n",
    "\n",
    "CountVectorizer_params = list(ParameterGrid({\n",
    "    'strip_accents': ['ascii', 'unicode', None],\n",
    "    'max_df': [round(0.1*x, 2) for x in range(3,11,2)] + [1],\n",
    "    'max_features': [1000*x for x in range(5,50,20)] + [None],\n",
    "}))\n",
    "\n",
    "HashingVectorizer_params = list(ParameterGrid({\n",
    "    'strip_accents': ['ascii', 'unicode', None],\n",
    "    'n_features': [2**x for x in range(15,25,2)],\n",
    "    'norm': ['l2'],\n",
    "    'alternate_sign': [False]\n",
    "}))\n",
    "\n",
    "# feature selector params\n",
    "SelectKBest_params = list(ParameterGrid({\n",
    "    'score_func': [chi2, f_classif, mutual_info_classif],\n",
    "    'k': [10000, 25000, 40000, 55000],\n",
    "    #'score_func': [chi2],\n",
    "    #'k': [30000, 35000, 40000]\n",
    "}))\n",
    "\n",
    "# scaler params\n",
    "MinMaxScaler_params = list(ParameterGrid({\n",
    "    'feature_range': [(0,1)]\n",
    "}))\n",
    "\n",
    "# classifier params\n",
    "MultinomialNB_params = list(ParameterGrid({\n",
    "    'alpha': [0.01, 0.0015, 0.001, 0.0005, 0.0001]\n",
    "}))\n",
    "\n",
    "LinearSVC_params = list(ParameterGrid({\n",
    "    #'loss': ['hinge', 'squared_hinge'],\n",
    "    #'tol': [0.01, 0.001, 0.0001, 0.00001],\n",
    "    #'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    #'class_weight': ['balanced', None]\n",
    "    'loss': ['squared_hinge'],\n",
    "    #'tol': [0.01, 0.005, 0.001, 0.0005],\n",
    "    'tol': [0.008, 0.01, 0.015, 0.02],\n",
    "    #'C': [0.5, 1, 1.5, 2],\n",
    "    'C': [0.1, 0.3, 0.5, 0.8],\n",
    "    #'C': [1],\n",
    "    #'class_weight': [None],\n",
    "    #'max_iter': [1500]\n",
    "}))\n",
    "\n",
    "ComplementNB_params = list(ParameterGrid({\n",
    "    'alpha': [0.1, 0.2, 0.5, 1]\n",
    "}))\n",
    "\n",
    "SGDClassifier_params = list(ParameterGrid({\n",
    "    'loss': ['hinge', 'log', 'squared_hinge', 'perceptron'],\n",
    "    'alpha': [0.001,0.0001, 0.00001, 0.000001],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [1]\n",
    "}))\n",
    "\n",
    "LogisticRegression_params = list(ParameterGrid({\n",
    "    'tol': [0.001, 0.0001, 0.00001, 0.000001],\n",
    "    'C': [6, 8, 10, 12],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga'],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [1]\n",
    "}))\n",
    "\n",
    "# sampler params\n",
    "ClusterCentroids_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['majority', 'not minority', 'all'],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "RandomUnderSampler_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['majority', 'auto'],\n",
    "    'replacement': [True, False]\n",
    "}))\n",
    "\n",
    "TomekLinks_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['majority', 'auto'],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "label_targets = {\n",
    "    #12: 2388,\n",
    "    #93: 2388,\n",
    "    #91: 2388,\n",
    "    15: 2000,\n",
    "    16: 2000,\n",
    "    20: 2000,\n",
    "    3: 2000,\n",
    "    10: 1500,\n",
    "    92: 1500,\n",
    "    17: 1500,\n",
    "    19: 1500,\n",
    "    4: 1000,\n",
    "    13: 1000,\n",
    "    1: 1000,\n",
    "    23: 1000,\n",
    "    8: 1000,\n",
    "    6: 1000,\n",
    "    7: 1000,\n",
    "    25: 1000,\n",
    "    5: 1000,\n",
    "    2: 1000,\n",
    "    9: 1000,\n",
    "    24: 800,\n",
    "    14: 800,\n",
    "    26: 800,\n",
    "    21: 800,\n",
    "    18: 800,\n",
    "}\n",
    "\n",
    "ADASYN_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['minority'],\n",
    "    'n_neighbors': [23, 27, 31, 33],\n",
    "    #'n_neighbors': [31,41,61,71,81],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "SMOTE_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['minority', 'auto'],\n",
    "    'k_neighbors': [3,5,7,13],\n",
    "    'n_jobs': [-1]\n",
    "}))\n",
    "\n",
    "RandomOverSampler_params = list(ParameterGrid({\n",
    "    'random_state': [1],\n",
    "    'sampling_strategy': ['minority', 'auto']\n",
    "}))\n",
    "\n",
    "CalibratedClassifierCV_params = list(ParameterGrid({\n",
    "    'cv': [3],\n",
    "    'method': ['sigmoid', 'isotonic']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature combinations\n",
    "feats = [\n",
    "    #('TextOnly', {'text': text}),\n",
    "    ('FTOnly', {'ft': fasttext}),\n",
    "    #('Text+FT', {'text': text, 'ft': fasttext}),\n",
    "    #('Text+DLWC', {'text': text, 'numeric': numeric}),\n",
    "    #('TextOnly', False),\n",
    "    #('TextPOS', pos_features),\n",
    "    #('TextONT', ont_features),\n",
    "    #('TextDLWC', numerical_features),\n",
    "    #('All', pos_features + ont_features + numerical_features),\n",
    "]\n",
    "\n",
    "\n",
    "# vectorizers\n",
    "vectorizers = [\n",
    "    #('No_vectorizer', u.PassThrough, [{}]),\n",
    "    #('TfidfVectorizer', TfidfVectorizer, [{}]),\n",
    "    #('TfidfVectorizer', TfidfVectorizer, [{'max_df': 0.3, 'max_features': None, 'norm': 'l2', 'strip_accents': 'ascii', 'use_idf': False}]),\n",
    "    #('TfidfVectorizer', TfidfVectorizer, TfidfVectorizer_params),\n",
    "    ('TfidfVectorizer', TfidfVectorizer, [{'lowercase': False, 'max_df': 0.25}]), \n",
    "    #('TfidfVectorizer', TfidfVectorizer, [{'lowercase': False, 'max_df': 0.25, 'tokenizer': tokenizer}]), \n",
    "    #('CountVectorizer', CountVectorizer, CountVectorizer_params),\n",
    "    #('HashingVectorizer', HashingVectorizer, HashingVectorizer_params),  \n",
    "]\n",
    "\n",
    "#corpus = ['empty']\n",
    "#fastt = False\n",
    "\n",
    "# feature selectors\n",
    "selectors = [\n",
    "    ('No_selector', u.PassThrough, [{}]),\n",
    "    #('SelectKBest', SelectKBest, [{'score_func': f_classif, 'k': 35000}]),\n",
    "    #('SelectKBest', SelectKBest, [{'score_func': chi2, 'k': 30000}]),\n",
    "    #('SelectKBest', SelectKBest, [{'score_func': chi2, 'k': 40000}]),\n",
    "    #('SelectKBest', SelectKBest, SelectKBest_params),\n",
    "]\n",
    "\n",
    "# scalers\n",
    "scalers = [\n",
    "    #('No_scaling', u.PassThrough, [{}]),\n",
    "    ('MinMaxScaler', MinMaxScaler, [{'feature_range': (0,1)}]),\n",
    "    #('MinMaxScaler', MinMaxScaler, MinMaxScaler_params),\n",
    "    #('MaxAbsScaler', MaxAbsScaler, [{}]),\n",
    "]\n",
    "\n",
    "\n",
    "clf_LinearSVC = LinearSVC(**{'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01})\n",
    "\n",
    "# classifiers\n",
    "classifiers = [\n",
    "    #('MultinomialNB', MultinomialNB, MultinomialNB_params),\n",
    "    #('LinearSVC', LinearSVC, LinearSVC_params),\n",
    "    ('LinearSVC', LinearSVC, [{'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}]),\n",
    "    #('CalibratedClassifierCV_LinearSVC', CalibratedClassifierCV, [{'base_estimator': clf_LinearSVC, 'method': 'isotonic', 'cv': 3}]),\n",
    "    #('ComplementNB', ComplementNB, ComplementNB_params),\n",
    "    #('ComplementNB', ComplementNB, [{'alpha': 0.2}]),\n",
    "    #('SGDClassifier', SGDClassifier, SGDClassifier_params),\n",
    "    #('SGDClassifier', SGDClassifier, [{'alpha': 0.00001, 'loss': 'log', 'n_jobs': -1, 'random_state': 1}]),\n",
    "    #('MultinomialNB', MultinomialNB, [{'alpha': 0.0015}]),\n",
    "    #('LogisticRegression', LogisticRegression, [{}]),\n",
    "    #('LogisticRegression', LogisticRegression, LogisticRegression_params),\n",
    "    #('LogisticRegression', LogisticRegression, [{'solver': 'saga', 'tol': 0.0001, 'C': 8, 'n_jobs': -1, 'random_state': 1}]),\n",
    "    #('SGDClassifier', SGDClassifier, [{}]),\n",
    "    #('LinearSVC', LinearSVC, [{}]),\n",
    "    #('MultinomialNB', MultinomialNB, [{}]),\n",
    "    #('ComplementNB', ComplementNB, [{}]),\n",
    "    #('LinearSVC', LinearSVC, [{'C': 1, 'class_weight': None, 'loss': 'hinge', 'tol': 0.01}]),\n",
    "    #('LinearSVC', LinearSVC, [{'C': 0.1, 'class_weight': None, 'loss': 'squared_hinge', 'tol': 0.01}]),\n",
    "    #('ComplementNB', ComplementNB, [{'alpha': 0.2, 'norm': False}]),\n",
    "    #('SGDClassifier', SGDClassifier, [{'alpha': 0.01, 'loss': 'hinge', 'n_jobs': -1}]),\n",
    "    #('LogisticRegression', LogisticRegression, [{'solver': 'lbfgs', 'multi_class': 'multinomial', 'max_iter': 500}]),\n",
    "    #('XGBClassifier', XGBClassifier, [{}]),\n",
    "    #('PassiveAggressiveClassifier', PassiveAggressiveClassifier, [{}]),\n",
    "    #('RandomForestClassifier', RandomForestClassifier, [{'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 3, 'random_state': 0}]),\n",
    "    #('MLPClassifier', MLPClassifier, [{'hidden_layer_sizes': (40,), 'max_iter': 500, 'alpha': 1e-4, 'solver': 'sgd', 'verbose': 10, 'random_state': 1, 'learning_rate_init': .1}]),\n",
    "    #('BucketClassifier', mt.BucketClassifier, [{'hashfunc': mhash, 'classifiers': [LogisticRegression(**{'solver': 'lbfgs', 'multi_class': 'multinomial'}) for _ in range(10)], 'judge': MultinomialNB(alpha=0.001), 'num_buckets': 8}]),\n",
    "    #('EnsembleClassifier', mt.EnsembleClassifier, [{'binary_clf': LogisticRegression, 'binary_clf_params': {'solver': 'lbfgs'}, 'bucket_clf': MultinomialNB, 'bucket_clf_params': {'alpha': 0.001}, 'judge': MultinomialNB(alpha=0.001)}]),\n",
    "]\n",
    "\n",
    "# samplers\n",
    "samplers = [\n",
    "    #('SMOTE', SMOTE, [{'random_state': 1, 'sampling_strategy': 'minority', 'k_neighbors': 3, 'n_jobs': -1}]),\n",
    "    #('SMOTE', SMOTE, [{'random_state': 1, 'sampling_strategy': 'minority', 'k_neighbors': 7, 'n_jobs': -1}]),\n",
    "    ('No_sampling', u.PassThrough, [{}]),\n",
    "    #('ClusterCentroids', ClusterCentroids, ClusterCentroids_params),\n",
    "    #('ClusterCentroids', ClusterCentroids, [{'random_state': 1, 'sampling_strategy': 'majority', 'n_jobs': -1}]),\n",
    "    #('RandomUnderSampler', RandomUnderSampler, RandomUnderSampler_params),\n",
    "    #('RandomUnderSampler', RandomUnderSampler, [{'random_state': 1, 'sampling_strategy': 'majority', 'replacement': False}]),\n",
    "    #('TomekLinks', TomekLinks, TomekLinks_params),\n",
    "    #('TomekLinks', TomekLinks, [{'random_state': 1, 'sampling_strategy': 'majority', 'n_jobs': -1}]),\n",
    "    #('ADASYN', ADASYN, ADASYN_params),\n",
    "    #('ADASYN', ADASYN, [{'n_jobs': -1, 'n_neighbors': 27, 'random_state': 1, 'sampling_strategy': 'minority'}]),\n",
    "    #('SMOTE', SMOTE, SMOTE_params),\n",
    "    #('SMOTE', SMOTE, [{'n_jobs': -1, 'k_neighbors': 3, 'random_state': 1, 'sampling_strategy': 'minority'}]),\n",
    "    #('RandomOverSampler', RandomOverSampler, RandomOverSampler_params),\n",
    "    #('RandomOverSampler', RandomOverSampler, [{'random_state': 1, 'sampling_strategy': 'minority'}]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/No_selector/MinMaxScaler\n",
      "{'lowercase': False, 'max_df': 0.25}\n",
      "{'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}\n",
      "{}\n",
      "{}\n",
      "{'feature_range': (0, 1)}\n",
      "0.6713174134692782 0.6715701110883445 0.6180819985345474 0.6303858624039064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>V.params</th>\n",
       "      <th>Selector</th>\n",
       "      <th>Sel.params</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Sca.params</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>C.params</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>S.params</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/No_selector/MinMaxScaler</td>\n",
       "      <td>FTOnly</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>{'lowercase': False, 'max_df': 0.25}</td>\n",
       "      <td>No_selector</td>\n",
       "      <td>{}</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>{'feature_range': (0, 1)}</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>{'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}</td>\n",
       "      <td>No_sampling</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.671317</td>\n",
       "      <td>0.67157</td>\n",
       "      <td>0.618082</td>\n",
       "      <td>0.630386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Features       Vectorizer  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...   FTOnly  TfidfVectorizer   \n",
       "\n",
       "                                                                                V.params  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  {'lowercase': False, 'max_df': 0.25}   \n",
       "\n",
       "                                                       Selector Sel.params  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  No_selector         {}   \n",
       "\n",
       "                                                          Scaler  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  MinMaxScaler   \n",
       "\n",
       "                                                                   Sca.params  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  {'feature_range': (0, 1)}   \n",
       "\n",
       "                                                   Classifier  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  LinearSVC   \n",
       "\n",
       "                                                                                            C.params  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  {'C': 0.5, 'loss': 'squared_hinge', 'tol': 0.01}   \n",
       "\n",
       "                                                        Sampler S.params  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  No_sampling       {}   \n",
       "\n",
       "                                                    Accuracy  Precision  \\\n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  0.671317    0.67157   \n",
       "\n",
       "                                                      Recall    Fscore  \n",
       "1_FTOnly/TfidfVectorizer/LinearSVC/No_sampling/...  0.618082  0.630386  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, preds_validation = u.model_iterator({\n",
    "    'train_X': train_X,\n",
    "    'train_y': train_y,\n",
    "    #'validation_X': validation_X,\n",
    "    #'validation_y': validation_y,\n",
    "    'validation_X': test_X,\n",
    "    'validation_y': test_y\n",
    "}, feats, vectorizers, classifiers, samplers, selectors, scalers)\n",
    "\n",
    "display(results.sort_values(by=['Accuracy', 'Precision'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5358802111241325"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(df['ft'].to_numpy()).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.0001},\n",
       " {'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-05},\n",
       " {'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-06},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.001},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-05},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-06},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.0001},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-05},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-06},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.0001},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.001},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.001},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-05},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-06},\n",
       " {'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.001},\n",
       " {'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.0001},\n",
       " {'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-05},\n",
       " {'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-06},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.001},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.001},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-05},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-06},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-05},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-06},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.001},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.0001},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-05},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-06},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.001},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.0001},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-05},\n",
       " {'C': 8,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-06},\n",
       " {'C': 8, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.001},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.001},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 0.0001},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-05},\n",
       " {'C': 6, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs', 'tol': 1e-06},\n",
       " {'C': 6,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.001},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.001},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.0001},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-05},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-06},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.001},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.001},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.001},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 0.0001},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-05},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'newton-cg',\n",
       "  'tol': 1e-06},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.0001},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-05},\n",
       " {'C': 10,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-06},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.0001},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-05},\n",
       " {'C': 12,\n",
       "  'n_jobs': -1,\n",
       "  'random_state': 1,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 1e-06},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.0001},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-05},\n",
       " {'C': 10, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-06},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.0001},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-05},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 1e-06},\n",
       " {'C': 12, 'n_jobs': -1, 'random_state': 1, 'solver': 'saga', 'tol': 0.001}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=['Accuracy', 'Precision'], ascending=False)['C.params'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc['71_TextOnly/TfidfVectorizer/LogisticRegression/No_sampling/No_selector/No_scaling']['C.params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results.sort_values(by=['Accuracy', 'Precision'], ascending=False).groupby('Classifier').head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(round(time.time()))\n",
    "results.to_pickle('../stats/'+timestamp+'_tfidfgrid_results.pkl')\n",
    "with open('../stats/'+timestamp+'_tfidfgrid_preds.pkl', 'wb') as f:\n",
    "    pickle.dump(preds_validation, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results.sort_values(by=['Accuracy', 'Precision'], ascending=False)['S.params'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = u.plot_cf(preds_validation['validation_y'], preds_validation['preds'][0], title = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(**{'lowercase': False, 'max_df': 0.25}) \n",
    "\n",
    "vec_train = vec.fit_transform(train_X[text])\n",
    "vec_test = vec.transform(vali_X[text])\n",
    "\n",
    "agg = FeatureAgglomeration(n_clusters=50)\n",
    "\n",
    "vec_train_reduced = agg.fit_transform(vec_train)\n",
    "vec_test_reduced = agg.transform(vec_test)\n",
    "\n",
    "clf = MultinomialNB(**{'alpha': 0.001})\n",
    "clf.fit(vec_train_reduced, train_y)\n",
    "\n",
    "preds = clf.predict(vec_test_reduced)\n",
    "\n",
    "np.mean(preds == vali_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
