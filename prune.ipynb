{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lda_directed import DirectedLDA\n",
    "\n",
    "import utils as u\n",
    "\n",
    "from co_train import Co_Train\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../pandas/lemma_delivered_merged_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_corpus = df[(df['agg_label'] != -1) & (df['agg_label'] < 90)]['lemma_delivered']\n",
    "#labeled_corpus = df[(df['agg_label'] != -1)]['lemma_delivered']\n",
    "target = df[(df['agg_label'] != -1) & (df['agg_label'] < 90)]['agg_label']\n",
    "#target = df[(df['agg_label'] != -1)]['agg_label']\n",
    "\n",
    "unlabeled_corpus = df[(df['agg_label'] == -1)]['lemma_delivered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, validation_X, train_y, validation_y = train_test_split(\n",
    "    labeled_corpus,\n",
    "    target,\n",
    "    test_size=0.33,\n",
    "    random_state=1,\n",
    "    stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prunor(X, y, v_X, v_y, prune_mask, best_prune_mask, best_acc, init_acc):\n",
    "    \n",
    "    vec = TfidfVectorizer(**{'tokenizer': lambda x: x.split(), 'lowercase': False, 'max_df': 0.3}) \n",
    "    vec_train_X = vec.fit_transform(X[prune_mask])\n",
    "    vec_validation = vec.transform(v_X)\n",
    "\n",
    "    clf = MultinomialNB(**{'alpha': 0.001})\n",
    "    clf.fit(vec_train_X, y[prune_mask])\n",
    "\n",
    "    train_prob = clf.predict_proba(vec_train_X)\n",
    "    train_max_probs = np.amax(train_prob, axis=1)\n",
    "    prune_mask = np.argwhere((train_max_probs > 0.5) & (train_max_probs < 1)).T[0]\n",
    "\n",
    "    clf_preds = clf.predict(vec_validation)\n",
    "    acc = np.mean(clf_preds == v_y)\n",
    "    \n",
    "    print(init_acc, acc, best_acc)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_prune_mask = prune_mask\n",
    "        best_acc = acc\n",
    "    \n",
    "    if acc < init_acc:\n",
    "        return best_prune_mask\n",
    "    else:\n",
    "        return prunor(X, y, v_X, v_y, prune_mask, best_prune_mask, best_acc, init_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6900387834251888\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(**{'tokenizer': lambda x: x.split(), 'lowercase': False, 'max_df': 0.3}) \n",
    "vec_train_X = vec.fit_transform(train_X)\n",
    "vec_validation = vec.transform(validation_X)\n",
    "\n",
    "clf = MultinomialNB(**{'alpha': 0.001})\n",
    "clf.fit(vec_train_X, train_y)\n",
    "\n",
    "train_prob = clf.predict_proba(vec_train_X)\n",
    "train_max_probs = np.amax(train_prob, axis=1)\n",
    "prune_mask = np.argwhere((train_max_probs > 0.5) & (train_max_probs < 1)).T[0]\n",
    "\n",
    "clf_preds = clf.predict(vec_validation)\n",
    "acc = np.mean(clf_preds == validation_y)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6900387834251888 0.6900387834251888 0.6900387834251888\n",
      "0.6900387834251888 0.69034496836089 0.6900387834251888\n",
      "0.6900387834251888 0.6902429067156562 0.69034496836089\n",
      "0.6900387834251888 0.6905490916513575 0.69034496836089\n",
      "0.6900387834251888 0.6909573382322923 0.6905490916513575\n",
      "0.6900387834251888 0.6904470300061237 0.6909573382322923\n",
      "0.6900387834251888 0.6902429067156562 0.6909573382322923\n",
      "0.6900387834251888 0.6906511532965911 0.6909573382322923\n",
      "0.6900387834251888 0.6905490916513575 0.6909573382322923\n",
      "0.6900387834251888 0.6909573382322923 0.6909573382322923\n",
      "0.6900387834251888 0.6902429067156562 0.6909573382322923\n",
      "0.6900387834251888 0.6906511532965911 0.6909573382322923\n",
      "0.6900387834251888 0.6911614615227597 0.6909573382322923\n",
      "0.6900387834251888 0.6901408450704225 0.6911614615227597\n",
      "0.6900387834251888 0.6913655848132272 0.6911614615227597\n",
      "0.6900387834251888 0.6904470300061237 0.6913655848132272\n",
      "0.6900387834251888 0.6910593998775261 0.6913655848132272\n",
      "0.6900387834251888 0.6913655848132272 0.6913655848132272\n",
      "0.6900387834251888 0.6914676464584609 0.6913655848132272\n",
      "0.6900387834251888 0.6914676464584609 0.6914676464584609\n",
      "0.6900387834251888 0.6910593998775261 0.6914676464584609\n",
      "0.6900387834251888 0.6906511532965911 0.6914676464584609\n",
      "0.6900387834251888 0.6905490916513575 0.6914676464584609\n",
      "0.6900387834251888 0.6899367217799551 0.6914676464584609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 19159, 19160, 19161], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_prune_mask = np.ones(len(train_y), dtype=bool)\n",
    "\n",
    "best_prune_mask = prunor(train_X, train_y, validation_X, validation_y, init_prune_mask, init_prune_mask, acc, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy = np.array([0,1,2,3,4])\n",
    "testy2 = testy[[0,2,3]]\n",
    "\n",
    "testy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.69034496836089\n",
      "1 0.6902429067156562\n",
      "2 0.6905490916513575\n",
      "3 0.6909573382322923\n",
      "4 0.6904470300061237\n",
      "5 0.6902429067156562\n",
      "6 0.6906511532965911\n",
      "7 0.6905490916513575\n",
      "8 0.6909573382322923\n",
      "9 0.6902429067156562\n",
      "10 0.6906511532965911\n",
      "11 0.6911614615227597\n",
      "12 0.6901408450704225\n",
      "13 0.6913655848132272\n",
      "14 0.6904470300061237\n",
      "15 0.6910593998775261\n",
      "16 0.6913655848132272\n",
      "17 0.6914676464584609\n",
      "18 0.6914676464584609\n",
      "19 0.6910593998775261\n",
      "20 0.6906511532965911\n",
      "21 0.6905490916513575\n",
      "22 0.6899367217799551\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-23dbe8d0aee2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'tokenizer'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lowercase'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_df'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mvec_train_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprune_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mvec_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \"\"\"\n\u001b[0;32m   1651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1652\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1058\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    981\u001b[0m             \u001b[0mj_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             \u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    vec = TfidfVectorizer(**{'tokenizer': lambda x: x.split(), 'lowercase': False, 'max_df': 0.3}) \n",
    "    vec_train_X = vec.fit_transform(train_X[prune_mask])\n",
    "    vec_validation = vec.transform(validation_X)\n",
    "\n",
    "    clf = MultinomialNB(**{'alpha': 0.001})\n",
    "    clf.fit(vec_train_X, train_y[prune_mask])\n",
    "\n",
    "    train_prob = clf.predict_proba(vec_train_X)\n",
    "    train_max_probs = np.amax(train_prob, axis=1)\n",
    "    prune_mask = np.argwhere((train_max_probs > 0.5) & (train_max_probs < 1)).T[0]\n",
    "\n",
    "    clf_preds = clf.predict(vec_validation)\n",
    "    acc = np.mean(clf_preds == validation_y)\n",
    "\n",
    "    print(i, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18388,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_mask.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
